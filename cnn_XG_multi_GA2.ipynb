{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StratifiedKFold, cross_val_score\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mxgb\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\__init__.py:82\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _distributor_init  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __check_build  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[0;32m     85\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    129\u001b[0m ]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _IS_32BIT\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_set_output\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _SetOutputMixin\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tags\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     _DEFAULT_TAGS,\n\u001b[0;32m     21\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\__init__.py:19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m issparse\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmurmurhash\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m murmurhash3_32\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclass_weight\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compute_class_weight, compute_sample_weight\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _joblib\n",
      "File \u001b[1;32msklearn\\utils\\murmurhash.pyx:1\u001b[0m, in \u001b[0;36minit sklearn.utils.murmurhash\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"Sklearn version: {sklearn.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SR=22050\n",
    "N_MFCC=40\n",
    "N_MELS=128\n",
    "DURATION=1\n",
    "SAMPLES_PER_TRACK=SR*DURATION\n",
    "#CLASSES=['AR','Sniper','nogun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = [\n",
    "    \"v3_exp1_test.csv\",\n",
    "    \"v3_exp1_train.csv\",\n",
    "    \"v3_exp2_test.csv\",\n",
    "    \"v3_exp2_train.csv\",\n",
    "    \"v3_exp3_test.csv\",\n",
    "    \"v3_exp3_train.csv\"\n",
    "]\n",
    "\n",
    "df = pd.concat([pd.read_csv(file) for file in file_names])\n",
    "\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path):\n",
    "    y,sr=librosa.load(file_path,sr=SR,duration=DURATION)\n",
    "    if len(y)<SAMPLES_PER_TRACK:\n",
    "        y=np.pad(y,(0,SAMPLES_PER_TRACK-len(y)))\n",
    "    else:\n",
    "        y=y[:SAMPLES_PER_TRACK]\n",
    "    mfcc=librosa.feature.mfcc(y=y,sr=sr,n_mfcc=N_MFCC)\n",
    "    mfcc=librosa.util.fix_length(mfcc,size=174,axis=1)\n",
    "    mfcc=mfcc[...,np.newaxis]\n",
    "\n",
    "    mel_spec=librosa.feature.melspectrogram(y=y,sr=sr)\n",
    "    mel_spec=librosa.power_to_db(mel_spec,ref=np.max)\n",
    "    mel_spec=librosa.util.fix_length(mel_spec,size=174,axis=1)\n",
    "    mel_spec=mel_spec[...,np.newaxis]\n",
    "    return mfcc,mel_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_dataset(dataset_path, dataset):\n",
    "    # Initialize lists to store features and labels\n",
    "    x_mfcc, x_melspec, gun_type, direction, distance = [], [], [], [], []\n",
    "\n",
    "    # Loop through all .wav files in the directory\n",
    "    for file_name in os.listdir(dataset_path):\n",
    "        if file_name.endswith(\".mp3\"):\n",
    "            # Get the full file path\n",
    "            file_path = os.path.join(dataset_path, file_name)\n",
    "\n",
    "\n",
    "            # Extract features\n",
    "            mfcc, mel_spec = extract_features(file_path)\n",
    "            x_mfcc.append(mfcc)\n",
    "            x_melspec.append(mel_spec)\n",
    "\n",
    "            # Check if the file is in the dataset DataFrame\n",
    "            row = dataset[dataset['name'] == file_name]\n",
    "\n",
    "                # Extract gun type, direction, and distance\n",
    "            gun_type.append(row['cate'].values[0])\n",
    "            direction.append(row['dire'].values[0])\n",
    "            distance.append(row['dist'].values[0])\n",
    "\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    x_mfcc = np.array(x_mfcc)\n",
    "    x_melspec = np.array(x_melspec)\n",
    "\n",
    "    # Encode gun type labels\n",
    "    gun_encoder = LabelEncoder()\n",
    "    gun_types_encoded = gun_encoder.fit_transform(gun_type)\n",
    "    gun_types_categorical = to_categorical(gun_types_encoded)\n",
    "\n",
    "    # Encode direction labels\n",
    "    direction_encoder = LabelEncoder()\n",
    "    direction_types_encoded = direction_encoder.fit_transform(direction)\n",
    "    direction_types_categorical = to_categorical(direction_types_encoded)\n",
    "\n",
    "    # Encode distance labels\n",
    "    distance_encoder = LabelEncoder()\n",
    "    distance_types_encoded = distance_encoder.fit_transform(distance)\n",
    "    distance_types_categorical = to_categorical(distance_types_encoded)\n",
    "\n",
    "    # Return the processed features and labels\n",
    "    return x_mfcc, x_melspec, gun_types_categorical, direction_types_categorical, distance_types_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mfcc,X_melspec,y_gun,y_direction,y_distance=load_dataset('data\\gun_sound_v2',dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_melspec_shape=X_melspec.shape\n",
    "X_melspec_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mfcc_shape=X_mfcc.shape\n",
    "X_mfcc_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_gun.shape,y_direction.shape,y_distance.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mfcc_train, X_mfcc_test, X_melspec_train, X_melspec_test, y_gun_train, y_gun_test,y_distance_train,y_distance_test,y_direction_train,y_direction_test = train_test_split(\n",
    "    X_mfcc, X_melspec, y_gun,y_distance,y_direction,test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Then, split the training+validation set into training and validation sets\n",
    "# X_mfcc_train, X_mfcc_val, X_melspec_train, X_melspec_val, y_gun_train, y_gun_val,y_distance_train,y_distance_val,y_direction_train,y_direction_val = train_test_split(\n",
    "#     X_mfcc_trainval, X_melspec_trainval, y_gun_trainval,y_distance_trainval,y_direction_trainval, test_size=0.3, random_state=42\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_gun_train=np.array(y_gun_train)\n",
    "y_gun_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mfcc_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape_mfcc,input_shape_melspec,num_classes=38,num_directions=6,num_distances=7):\n",
    "    input_mfcc=Input(shape=input_shape_mfcc,name='mfcc_input')\n",
    "    x_mfcc=Conv2D(16,kernel_size=(3,3),activation='relu')(input_mfcc)\n",
    "    x_mfcc=MaxPooling2D(pool_size=(2,2))(x_mfcc)\n",
    "    x_mfcc=Dropout(0.3)(x_mfcc)\n",
    "\n",
    "    x_mfcc=Conv2D(32,kernel_size=(3,3),activation='relu')(x_mfcc)\n",
    "    x_mfcc=MaxPooling2D(pool_size=(2,2))(x_mfcc)\n",
    "    x_mfcc=Dropout(0.3)(x_mfcc)\n",
    "\n",
    "    x_mfcc=Conv2D(64,kernel_size=(3,3),activation='relu')(x_mfcc)\n",
    "    x_mfcc=MaxPooling2D(pool_size=(1,2))(x_mfcc)\n",
    "    x_mfcc=Dropout(0.3)(x_mfcc)\n",
    "    \n",
    "    x_mfcc=Conv2D(128,kernel_size=(3,3),activation='relu')(x_mfcc)\n",
    "    x_mfcc=MaxPooling2D(pool_size=(2,2))(x_mfcc)\n",
    "    x_mfcc=Dropout(0.3)(x_mfcc)\n",
    "    \n",
    "    x_mfcc=GlobalAveragePooling2D()(x_mfcc)\n",
    "\n",
    "    input_melspec=Input(shape=input_shape_melspec,name='melspec_input')\n",
    "    x_melspec=Conv2D(16,kernel_size=(3,3),activation='relu')(input_melspec)\n",
    "    x_melspec=MaxPooling2D(pool_size=(2,2))(x_melspec)\n",
    "    x_melspec=Dropout(0.3)(x_melspec)\n",
    "\n",
    "    x_melspec=Conv2D(32,kernel_size=(3,3),activation='relu')(x_melspec)\n",
    "    x_melspec=MaxPooling2D(pool_size=(2,2))(x_melspec)\n",
    "    x_melspec=Dropout(0.3)(x_melspec)\n",
    "\n",
    "    x_melspec=Conv2D(64,kernel_size=(3,3),activation='relu')(x_melspec)\n",
    "    x_melspec=MaxPooling2D(pool_size=(2,2))(x_melspec)\n",
    "    x_melspec=Dropout(0.3)(x_melspec)\n",
    "\n",
    "    x_melspec=Conv2D(128,kernel_size=(3,3),activation='relu')(x_melspec)\n",
    "    x_melspec=MaxPooling2D(pool_size=(2,2))(x_melspec)\n",
    "    x_melspec=Dropout(0.3)(x_melspec)\n",
    "\n",
    "    x_melspec = GlobalAveragePooling2D()(x_melspec)\n",
    "\n",
    "    concatenated=tf.keras.layers.concatenate([x_mfcc,x_melspec])\n",
    "    common_dense=Dense(128,activation='relu',name='concatenated')(concatenated)\n",
    "    gunshot_output=Dense(num_classes,activation='softmax',name='gunshot_output')(common_dense)\n",
    "    direction_output=Dense(num_directions,activation='softmax',name='direction_output')(common_dense)\n",
    "    distance_output=Dense(num_distances,activation='softmax',name='distance_output')(common_dense)\n",
    "\n",
    "    model=Model(inputs=[input_mfcc,input_melspec],outputs=[gunshot_output,direction_output,distance_output])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_extractor(input_shape_mfcc, input_shape_melspec):\n",
    "    model = create_model(input_shape_mfcc, input_shape_melspec)\n",
    "    feature_extractor = Model(inputs=model.inputs, outputs=model.get_layer('concatenated').output)\n",
    "    return model,feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape_mfcc=(40,174,1)\n",
    "input_shape_melspec=(128,174,1)\n",
    "model,feature_extractor=create_feature_extractor(input_shape_mfcc,input_shape_melspec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss={\n",
    "                    'gunshot_output':'categorical_crossentropy',\n",
    "                    'direction_output':'categorical_crossentropy',\n",
    "                    'distance_output':'categorical_crossentropy'},\n",
    "                metrics={\n",
    "                    'gunshot_output': ['accuracy', AUC()],\n",
    "                    'distance_output': ['accuracy', AUC()],\n",
    "                    'direction_output': ['accuracy', AUC()]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "batch_size=32\n",
    "valid_batch_size=32\n",
    "callbacks=[ModelCheckpoint(\"best_model.keras\",monitor='val_loss')]\n",
    "\n",
    "history=model.fit([X_mfcc_train,X_melspec_train],\n",
    "                  {\n",
    "                      'gunshot_output':y_gun_train,\n",
    "                      'direction_output':y_direction_train,\n",
    "                      'distance_output':y_distance_train\n",
    "                  },\n",
    "                  validation_data=([X_mfcc_test,X_melspec_test],\n",
    "                                    {\n",
    "                                        'gunshot_output':y_gun_test,\n",
    "                                        'direction_output':y_direction_test,\n",
    "                                        'distance_output':y_distance_test\n",
    "                                    }),\n",
    "                    epochs=128,batch_size=32,callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=feature_extractor.predict([X_mfcc,X_melspec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer_name='concatenated'\n",
    "# intermediate_layer_model=Model(inputs=model.input,outputs=model.get_layer(layer_name).output)\n",
    "# intermediate_layer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_gun.shape,y_direction.shape,y_distance.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_combined = np.column_stack((y_gun, y_direction, y_distance))\n",
    "X_train,X_test,y_train_combined,y_test_combined=train_test_split(features ,y_combined,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_gun_train_onehot = y_train_combined[:, :38]\n",
    "y_gun_test_onehot = y_test_combined[:, :38]\n",
    "y_gun_train = np.argmax(y_gun_train_onehot, axis=1)\n",
    "y_gun_test = np.argmax(y_gun_test_onehot, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dir_train_onehot = y_train_combined[:,38:44]\n",
    "y_dir_test_onehot = y_test_combined[:,38:44]\n",
    "y_dir_train = np.argmax(y_dir_train_onehot, axis=1)\n",
    "y_dir_test = np.argmax(y_dir_test_onehot, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dist_train_onehot = y_train_combined[:,44:51]\n",
    "y_dist_test_onehot = y_test_combined[:,44:51]\n",
    "y_dist_train = np.argmax(y_dist_train_onehot, axis=1)\n",
    "y_dist_test = np.argmax(y_dist_test_onehot, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Stratified K-Fold for class balance in each fold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def objective_function_gun(params):\n",
    "    model = xgb.XGBClassifier(\n",
    "        n_estimators=int(params[0]),\n",
    "        max_depth=int(params[1]),\n",
    "        learning_rate=params[2],\n",
    "        subsample=params[3],\n",
    "        colsample_bytree=params[4],\n",
    "        gamma=params[5],\n",
    "        use_label_encoder=False,  # For newer versions of XGBoost\n",
    "        eval_metric='mlogloss'    # For classification stability\n",
    "    )\n",
    "    # Using cross_val_score with StratifiedKFold\n",
    "    cv_score = cross_val_score(model, X_train_scaled, y_gun_train, cv=skf, scoring=\"accuracy\")\n",
    "    return -cv_score.mean()  # Return negative score for minimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function_dir(params):\n",
    "    model = xgb.XGBClassifier(\n",
    "        n_estimators=int(params[0]),\n",
    "        max_depth=int(params[1]),\n",
    "        learning_rate=params[2],\n",
    "        subsample=params[3],\n",
    "        colsample_bytree=params[4],\n",
    "        gamma=params[5],\n",
    "        use_label_encoder=False,  # For newer versions of XGBoost\n",
    "        eval_metric='mlogloss'    # For classification stability\n",
    "    )\n",
    "    # Using cross_val_score with StratifiedKFold\n",
    "    cv_score = cross_val_score(model, X_train_scaled, y_dir_train, cv=skf, scoring=\"accuracy\")\n",
    "    return -cv_score.mean()  # Return negative score for minimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function_dist(params):\n",
    "    model = xgb.XGBClassifier(\n",
    "        n_estimators=int(params[0]),\n",
    "        max_depth=int(params[1]),\n",
    "        learning_rate=params[2],\n",
    "        subsample=params[3],\n",
    "        colsample_bytree=params[4],\n",
    "        gamma=params[5],\n",
    "        use_label_encoder=False,  # For newer versions of XGBoost\n",
    "        eval_metric='mlogloss'    # For classification stability\n",
    "    )\n",
    "    # Using cross_val_score with StratifiedKFold\n",
    "    cv_score = cross_val_score(model, X_train_scaled, y_dist_train, cv=skf, scoring=\"accuracy\")\n",
    "    return -cv_score.mean()  # Return negative score for minimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_ranges = {\n",
    "    'n_estimators': (50, 500),\n",
    "    'max_depth': (3, 12),\n",
    "    'learning_rate': (0.01, 0.3),\n",
    "    'subsample': (0.5, 1.0),\n",
    "    'colsample_bytree': (0.5, 1.0),\n",
    "    'gamma': (0, 10)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def initialize_population(pop_size, param_ranges):\n",
    "    population = []\n",
    "    for _ in range(pop_size):\n",
    "        individual = [\n",
    "            np.random.randint(*param_ranges['n_estimators']),\n",
    "            np.random.randint(*param_ranges['max_depth']),\n",
    "            np.random.uniform(*param_ranges['learning_rate']),\n",
    "            np.random.uniform(*param_ranges['subsample']),\n",
    "            np.random.uniform(*param_ranges['colsample_bytree']),\n",
    "            np.random.uniform(*param_ranges['gamma']),\n",
    "        ]\n",
    "        population.append(individual)\n",
    "    return np.array(population)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(parent1, parent2, crossover_rate=0.5):\n",
    "    if np.random.rand() < crossover_rate:\n",
    "        crossover_point = np.random.randint(1, len(parent1) - 1)\n",
    "        child1 = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n",
    "        child2 = np.concatenate((parent2[:crossover_point], parent1[crossover_point:]))\n",
    "        return child1, child2\n",
    "    return parent1, parent2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(individual, mutation_rate=0.1):\n",
    "    for i in range(len(individual)):\n",
    "        if np.random.rand() < mutation_rate:  # Decide whether to mutate this parameter\n",
    "            if isinstance(param_ranges[list(param_ranges.keys())[i]], tuple):  # If the range is a tuple (min, max)\n",
    "                # Generate a new random float within the given range\n",
    "                min_val, max_val = param_ranges[list(param_ranges.keys())[i]]\n",
    "                individual[i] = np.random.uniform(min_val, max_val)\n",
    "            else:  # For integer parameters\n",
    "                individual[i] = np.random.randint(param_ranges[list(param_ranges.keys())[i]])\n",
    "    return individual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection(population, fitness, tournament_size=3):\n",
    "    selected = []\n",
    "    for _ in range(len(population)):\n",
    "        # Randomly select individuals for the tournament\n",
    "        tournament_indices = np.random.choice(len(population), tournament_size, replace=False)\n",
    "        tournament_fitness = fitness[tournament_indices]\n",
    "        # Select the best individual from the tournament\n",
    "        best_index = tournament_indices[np.argmin(tournament_fitness)]\n",
    "        selected.append(population[best_index])\n",
    "    return np.array(selected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genetic_algorithm_gun(pop_size, generations):\n",
    "    population = initialize_population(pop_size, param_ranges)\n",
    "    for gen in range(generations):\n",
    "        fitness = np.array([objective_function_gun(ind) for ind in population])\n",
    "        selected = selection(population, fitness)\n",
    "        next_gen = []\n",
    "        for i in range(0, len(selected), 2):\n",
    "            parent1, parent2 = selected[i], selected[i+1]\n",
    "            child1, child2 = crossover(parent1, parent2)\n",
    "            next_gen.append(mutate(child1))\n",
    "            next_gen.append(mutate(child2))\n",
    "        population = np.array(next_gen)\n",
    "    best_individual = population[np.argmin([objective_function_gun(ind) for ind in population])]\n",
    "    return best_individual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genetic_algorithm_dir(pop_size, generations):\n",
    "    population = initialize_population(pop_size, param_ranges)\n",
    "    for gen in range(generations):\n",
    "        fitness = np.array([objective_function_dir(ind) for ind in population])\n",
    "        selected = selection(population, fitness)\n",
    "        next_gen = []\n",
    "        for i in range(0, len(selected), 2):\n",
    "            parent1, parent2 = selected[i], selected[i+1]\n",
    "            child1, child2 = crossover(parent1, parent2)\n",
    "            next_gen.append(mutate(child1))\n",
    "            next_gen.append(mutate(child2))\n",
    "        population = np.array(next_gen)\n",
    "    best_individual = population[np.argmin([objective_function_dir(ind) for ind in population])]\n",
    "    return best_individual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genetic_algorithm_dist(pop_size, generations):\n",
    "    population = initialize_population(pop_size, param_ranges)\n",
    "    for gen in range(generations):\n",
    "        fitness = np.array([objective_function_dist(ind) for ind in population])\n",
    "        selected = selection(population, fitness)\n",
    "        next_gen = []\n",
    "        for i in range(0, len(selected), 2):\n",
    "            parent1, parent2 = selected[i], selected[i+1]\n",
    "            child1, child2 = crossover(parent1, parent2)\n",
    "            next_gen.append(mutate(child1))\n",
    "            next_gen.append(mutate(child2))\n",
    "        population = np.array(next_gen)\n",
    "    best_individual = population[np.argmin([objective_function_dist(ind) for ind in population])]\n",
    "    return best_individual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_gun=genetic_algorithm_gun(6,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimized Hyperparameters:\")\n",
    "print(f\"n_estimators: {ans_gun[0]}\")\n",
    "print(f\"max_depth: {ans_gun[1]}\")\n",
    "print(f\"learning_rate: {ans_gun[2]}\")\n",
    "print(f\"subsample: {ans_gun[3]}\")\n",
    "print(f\"colsample_bytree: {ans_gun[4]}\")\n",
    "print(f\"gamma: {ans_gun[5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_dir=genetic_algorithm_dir(8,10)\n",
    "print(\"Optimized Hyperparameters:\")\n",
    "print(f\"n_estimators: {ans_dir[0]}\")\n",
    "print(f\"max_depth: {ans_dir[1]}\")\n",
    "print(f\"learning_rate: {ans_dir[2]}\")\n",
    "print(f\"subsample: {ans_dir[3]}\")\n",
    "print(f\"colsample_bytree: {ans_dir[4]}\")\n",
    "print(f\"gamma: {ans_dir[5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_dist=genetic_algorithm_dist(6,10)\n",
    "print(\"Optimized Hyperparameters:\")\n",
    "print(f\"n_estimators: {ans_dist[0]}\")\n",
    "print(f\"max_depth: {ans_dist[1]}\")\n",
    "print(f\"learning_rate: {ans_dist[2]}\")\n",
    "print(f\"subsample: {ans_dist[3]}\")\n",
    "print(f\"colsample_bytree: {ans_dist[4]}\")\n",
    "print(f\"gamma: {ans_dist[5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xgb_model_gun=xgb.XGBClassifier(\n",
    "        n_estimators=int(ans_gun[0]),\n",
    "        max_depth=int(ans_gun[1]),\n",
    "        learning_rate=ans_gun[2],\n",
    "        subsample=ans_gun[3],\n",
    "        colsample_bytree=ans_gun[4],\n",
    "        gamma=ans_gun[5],\n",
    "        use_label_encoder=False,  \n",
    "        eval_metric='mlogloss'   \n",
    "    )\n",
    "xgb_model_gun.fit(X_train,y_gun_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgb_model_direction = xgb.XGBClassifier(\n",
    "        n_estimators=int(ans_dir[0]),\n",
    "        max_depth=int(ans_dir[1]),\n",
    "        learning_rate=ans_dir[2],\n",
    "        subsample=ans_dir[3],\n",
    "        colsample_bytree=ans_dir[4],\n",
    "        gamma=ans_dir[5],\n",
    "        use_label_encoder=False,  \n",
    "        eval_metric='mlogloss'    \n",
    "    )\n",
    "xgb_model_direction.fit(X_train, y_dir_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgb_model_distance = xgb.XGBClassifier(\n",
    "        n_estimators=int(ans_dist[0]),\n",
    "        max_depth=int(ans_dist[1]),\n",
    "        learning_rate=ans_dist[2],\n",
    "        subsample=ans_dist[3],\n",
    "        colsample_bytree=ans_dist[4],\n",
    "        gamma=ans_dist[5],\n",
    "        use_label_encoder=False,  \n",
    "        eval_metric='mlogloss',   \n",
    "    )\n",
    "xgb_model_distance.fit(X_train, y_dist_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "gun_type_pred=xgb_model_gun.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction_type_pred = xgb_model_direction.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "distance_type_pred = xgb_model_distance.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Evaluate accuracy for gun type\n",
    "gun_accuracy = accuracy_score(y_gun_test, gun_type_pred)\n",
    "print(f\"Accuracy for gun type classification: {gun_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "direction_accuracy = accuracy_score(y_dir_test, direction_type_pred)\n",
    "print(f\"Accuracy for direction type classification: {direction_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_accuracy = accuracy_score(y_dist_test, distance_type_pred)\n",
    "print(f\"Accuracy for distance type classification: {distance_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Gun type classification report\n",
    "print(\"Gun Type Classification Report\")\n",
    "print(classification_report(y_gun_test, gun_type_pred))\n",
    "\n",
    "# Direction type classification report\n",
    "print(\"Direction Type Classification Report\")\n",
    "print(classification_report(y_dir_test, direction_type_pred))\n",
    "\n",
    "# Distance type classification report\n",
    "print(\"Distance Type Classification Report\")\n",
    "print(classification_report(y_dist_test, distance_type_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm_gun = confusion_matrix(y_gun_test, gun_type_pred)\n",
    "sns.heatmap(cm_gun, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Gun Type Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_direction = confusion_matrix(y_dir_test, direction_type_pred)\n",
    "sns.heatmap(cm_direction, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Direction Type Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_distance = confusion_matrix(y_dist_test, distance_type_pred)\n",
    "sns.heatmap(cm_distance, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Distance Type Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "plt.clf()\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "                    y=history.history['gunshot_output_accuracy'],\n",
    "                    name='Train'))\n",
    "fig.add_trace(go.Scatter(\n",
    "                    y=history.history['val_gunshot_output_accuracy'],\n",
    "                    name='Valid'))\n",
    "fig.update_layout(height=500, \n",
    "                  width=700,\n",
    "                  title='Accuracy for gunshot feature',\n",
    "                  xaxis_title='Epoch',\n",
    "                  yaxis_title='Accuracy')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "                    y=history.history['direction_output_accuracy'],\n",
    "                    name='Train'))\n",
    "fig.add_trace(go.Scatter(\n",
    "                    y=history.history['val_direction_output_accuracy'],\n",
    "                    name='Valid'))\n",
    "fig.update_layout(height=500, \n",
    "                  width=700,\n",
    "                  title='Accuracy for direction feature',\n",
    "                  xaxis_title='Epoch',\n",
    "                  yaxis_title='Accuracy')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "                    y=history.history['distance_output_accuracy'],\n",
    "                    name='Train'))\n",
    "fig.add_trace(go.Scatter(\n",
    "                    y=history.history['val_distance_output_accuracy'],\n",
    "                    name='Valid'))\n",
    "fig.update_layout(height=500, \n",
    "                  width=700,\n",
    "                  title='Accuracy for distance feature',\n",
    "                  xaxis_title='Epoch',\n",
    "                  yaxis_title='Accuracy')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_history(history, model_name):\n",
    "    metrics = [\"accuracy\"]\n",
    "    for metric in metrics:\n",
    "\n",
    "        plt.plot(\n",
    "            history.history[f\"val_{model_name}_{metric}\"],\n",
    "            label=f\"Validation {metric}\",\n",
    "        )\n",
    "        plt.title(f\"{model_name.capitalize()} {metric.capitalize()} Over Epochs\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(metric.capitalize())\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "\n",
    "# Plot training history for each output of the neural network\n",
    "plot_training_history(history, \"gunshot_output\")\n",
    "plot_training_history(history, \"direction_output\")\n",
    "plot_training_history(history, \"distance_output\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.to_csv('model1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
